# El Sistema de Cach√©: Acelerando el Sistema

## Chequeo Digital 2.0 - C√≥mo Hicimos que las Consultas Costosas se Sientan Instant√°neas

---

## El Problema: Consultas que Tomaban una Eternidad

Cuando empezamos a trabajar en Chequeo Digital 2.0, nos enfrentamos a un problema serio de rendimiento. Las consultas de KPIs de rechequeos tomaban m√°s de 30 segundos en ejecutarse. Treinta segundos. Eso es suficiente tiempo para que un usuario se pregunte si el sistema se congel√≥, cierre la pesta√±a, y nunca vuelva.

El problema no era solo que las consultas eran lentas, sino que eran consultas que se repet√≠an constantemente. Cada vez que alguien abr√≠a la p√°gina de rechequeos, el sistema ten√≠a que recalcular todo desde cero: identificar empresas con m√∫ltiples chequeos, validar intervalos de 6 meses, calcular deltas, agregar por sector y departamento, etc.

Y lo peor: si diez usuarios abr√≠an la p√°gina al mismo tiempo, el sistema ejecutaba la misma consulta costosa diez veces, sobrecargando la base de datos y haciendo que todo fuera a√∫n m√°s lento.

---

## La Soluci√≥n: Cach√© Inteligente

La soluci√≥n fue implementar un sistema de cach√© multinivel. La idea es simple: si alguien ya calcul√≥ estos KPIs hace 2 minutos, y los datos no han cambiado, ¬øpor qu√© recalcularlos? Simplemente devolvemos los resultados que ya calculamos.

Pero no es tan simple como parece. Necesitamos:

1. **Decidir qu√© cachear**: No todo debe ser cacheado. Datos que cambian constantemente no deber√≠an cachearse, o deber√≠an tener un TTL (Time To Live) muy corto.

2. **Decidir cu√°nto tiempo cachear**: Si cacheamos por demasiado tiempo, los usuarios ven datos desactualizados. Si cacheamos por muy poco tiempo, no obtenemos los beneficios de rendimiento.

3. **Invalidar el cach√© cuando sea necesario**: Si alguien edita una empresa, necesitamos invalidar el cach√© relacionado para que los cambios se reflejen.

4. **Manejar fallos gracefully**: Si Redis (nuestro sistema de cach√© principal) no est√° disponible, el sistema debe seguir funcionando, aunque sea m√°s lento.

---

## La Arquitectura: Tres Niveles de Cach√©

Implementamos un sistema de tres niveles que trabaja en conjunto:

### Nivel 1: Cach√© en el Navegador (Service Worker)

El primer nivel es el m√°s cercano al usuario: el navegador. Usamos un Service Worker para cachear recursos est√°ticos como im√°genes, CSS, y JavaScript. Esto significa que cuando un usuario vuelve a visitar el sitio, estos recursos se cargan instant√°neamente desde el cach√© del navegador en lugar de descargarlos nuevamente del servidor.

Sin embargo, no cacheamos las llamadas a la API en el navegador porque los datos cambian frecuentemente y queremos asegurarnos de que los usuarios siempre vean informaci√≥n actualizada.

### Nivel 2: Cach√© en el Servidor (Redis + Memoria)

Este es el nivel m√°s importante. Cuando el backend necesita datos, primero verifica si est√°n en cach√©. Si est√°n, los devuelve inmediatamente sin tocar la base de datos. Si no est√°n, consulta la base de datos, guarda los resultados en cach√©, y luego los devuelve.

Usamos **Redis** como sistema de cach√© principal porque es extremadamente r√°pido (est√° en memoria) y puede ser compartido entre m√∫ltiples instancias del servidor. Pero tambi√©n implementamos un fallback a cach√© en memoria del servidor, as√≠ que si Redis no est√° disponible, el sistema sigue funcionando, solo que el cach√© no se comparte entre instancias.

### Nivel 3: Vistas Optimizadas en SQL Server

Aunque t√©cnicamente no es "cach√©" en el sentido tradicional, las vistas SQL optimizadas act√∫an como una forma de cach√© a nivel de base de datos. Pre-calculan valores complejos para que las consultas sean m√°s r√°pidas.

---

## C√≥mo Funciona el Flujo de Cach√©

D√©jame explicarte qu√© sucede cuando un usuario solicita los KPIs de rechequeos:

1. El frontend env√≠a una petici√≥n `GET /api/rechequeos/kpis?departamento=Capital`
2. El backend recibe la petici√≥n y genera una clave de cach√© √∫nica basada en los par√°metros: `rechequeos:kpis:{"departamento":"Capital"}`
3. El backend verifica si hay datos en cach√© con esa clave
4. **Si hay cach√© (HIT)**: Devuelve los datos inmediatamente (menos de 100ms)
5. **Si no hay cach√© (MISS)**:
   - Consulta la base de datos usando las vistas optimizadas (1-2 segundos)
   - Guarda los resultados en cach√© con un TTL de 5 minutos
   - Devuelve los datos al frontend

La pr√≥xima vez que alguien (o incluso la misma persona) solicite los mismos KPIs con los mismos filtros dentro de los pr√≥ximos 5 minutos, obtendr√° una respuesta casi instant√°nea desde el cach√©.

---

## Generaci√≥n de Claves: La Ciencia de Identificar Datos √önicos

Una parte crucial del sistema de cach√© es c√≥mo generamos las claves. Necesitamos que cada combinaci√≥n √∫nica de par√°metros tenga su propia clave, pero tambi√©n necesitamos que la misma combinaci√≥n siempre genere la misma clave.

Por ejemplo, si alguien solicita KPIs con `departamento=Capital&sector=Comercio`, y luego otra persona solicita con `sector=Comercio&departamento=Capital` (mismos par√°metros, diferente orden), ambas peticiones deber√≠an usar la misma clave de cach√©.

Nuestra soluci√≥n es ordenar los par√°metros alfab√©ticamente antes de generar la clave. Tambi√©n normalizamos arrays (los ordenamos) y filtramos valores vac√≠os o nulos. Esto asegura consistencia.

---

## TTL: Cu√°nto Tiempo Cachear

No todos los datos deben cachearse por el mismo tiempo. Algunos datos cambian frecuentemente, otros son m√°s estables:

- **KPIs de Rechequeos**: 5 minutos. Son c√°lculos costosos pero los datos subyacentes no cambian constantemente.
- **Listado de Empresas**: 2 minutos. Las empresas se crean y editan m√°s frecuentemente.
- **Detalle de Empresa**: 5 minutos. Los detalles de una empresa espec√≠fica son relativamente estables.
- **Opciones de Filtros**: 10 minutos. Los cat√°logos (departamentos, sectores, etc.) son muy estables.

Estos TTLs son un balance entre rendimiento y actualidad de datos. Si un usuario edita una empresa, invalidamos el cach√© relacionado inmediatamente, as√≠ que no tiene que esperar a que expire el TTL.

---

## Invalidaci√≥n: Cuando los Datos Cambian

Una de las partes m√°s importantes del sistema de cach√© es la invalidaci√≥n. Cuando alguien edita una empresa, no queremos que los usuarios sigan viendo los datos antiguos en cach√©. Necesitamos invalidar (eliminar) las entradas de cach√© relacionadas.

Implementamos invalidaci√≥n por patrones. Por ejemplo, cuando se edita una empresa, invalidamos todas las claves que empiezan con `empresas:*` y `rechequeos:*` (porque los rechequeos dependen de datos de empresas).

La invalidaci√≥n funciona tanto en Redis como en el cach√© de memoria. Buscamos todas las claves que coinciden con el patr√≥n y las eliminamos.

---

## Fallback a Memoria: Nunca Fallar

Una de las decisiones de dise√±o m√°s importantes fue hacer que el sistema funcione incluso si Redis no est√° disponible. Esto es crucial porque:

1. No todos los entornos tienen Redis instalado
2. Redis puede fallar o no estar disponible temporalmente
3. Queremos que el sistema sea f√°cil de instalar y usar

Entonces, el sistema siempre intenta usar Redis primero. Si Redis est√° disponible y conectado, lo usa. Si no est√° disponible, autom√°ticamente cambia a cach√© en memoria sin que el usuario note la diferencia.

El √∫nico downside es que con cach√© en memoria, cada instancia del servidor tiene su propio cach√© (no se comparte entre instancias), pero para la mayor√≠a de los casos de uso, esto es aceptable.

---

## Monitoreo: Saber Qu√© Est√° Pasando

Es importante saber c√≥mo est√° funcionando el sistema de cach√©. ¬øCu√°ntas veces encontramos datos en cach√© (HIT) vs. cu√°ntas veces tuvimos que consultar la base de datos (MISS)? ¬øRedis est√° funcionando correctamente? ¬øCu√°ntas entradas hay en cach√©?

Implementamos logging detallado que muestra:
- `‚úÖ Redis HIT: [clave]` - Encontramos datos en Redis
- `‚úÖ Memory HIT: [clave]` - Encontramos datos en memoria
- `‚ùå Cache MISS: [clave]` - No encontramos datos, consultamos BD
- `üóëÔ∏è Deleted X keys matching: [patr√≥n]` - Invalidaci√≥n de cach√©

Tambi√©n tenemos un endpoint de salud (`/health`) que muestra el estado del cach√©: si Redis est√° disponible, cu√°ntas entradas hay en memoria, etc.

---

## Limpieza Autom√°tica: Manteniendo el Cach√© Limpio

El cach√© en memoria necesita limpieza peri√≥dica. Si no eliminamos entradas expiradas, la memoria del servidor se llenar√≠a eventualmente.

Implementamos un proceso que se ejecuta cada minuto y elimina todas las entradas cuyo TTL ha expirado. Esto mantiene el cach√© de memoria limpio y eficiente.

---

## El Impacto Real

Despu√©s de implementar el sistema de cach√©, los tiempos de respuesta mejoraron dram√°ticamente:

- **Primera carga**: 1.2 segundos (consultando BD)
- **Cargas subsecuentes**: Menos de 100ms (desde cach√©)

Esto significa que si diez usuarios abren la p√°gina de rechequeos en un per√≠odo de 5 minutos, solo la primera petici√≥n consulta la base de datos. Las otras nueve obtienen datos desde cach√© casi instant√°neamente.

Pero el impacto va m√°s all√° de los n√∫meros. Los usuarios ahora tienen una experiencia fluida. No hay esperas largas. El sistema se siente r√°pido y responsivo. Y eso hace que los usuarios quieran usarlo m√°s.

---

## Configuraci√≥n: Haciendo que Funcione en Cualquier Entorno

El sistema est√° dise√±ado para funcionar en cualquier entorno, con o sin Redis:

**Con Redis (Recomendado)**:
- Instalar Memurai (para Windows) o Redis
- Configurar variables de entorno
- El sistema detecta Redis autom√°ticamente y lo usa

**Sin Redis**:
- No hacer nada especial
- El sistema detecta que Redis no est√° disponible
- Autom√°ticamente usa cach√© en memoria
- Funciona perfectamente, solo que el cach√© no se comparte entre instancias

Esta flexibilidad hace que el sistema sea f√°cil de instalar y usar, incluso para personas que no est√°n familiarizadas con Redis.

---

## Lecciones Aprendidas

Una de las lecciones m√°s importantes que aprendimos es que el cach√© no es solo una optimizaci√≥n t√©cnica, es una caracter√≠stica de experiencia de usuario. Los usuarios no saben (ni les importa) que estamos usando Redis o cach√© en memoria. Solo saben que el sistema es r√°pido.

Otra lecci√≥n es que la invalidaci√≥n es tan importante como el almacenamiento. Un cach√© con datos desactualizados es peor que no tener cach√© en absoluto, porque los usuarios toman decisiones basadas en informaci√≥n incorrecta.

Finalmente, aprendimos que la simplicidad es clave. El sistema de cach√© es robusto y funcional, pero tambi√©n es simple de entender y mantener. No sobre-ingeniamos la soluci√≥n.

---

## El Futuro del Cach√©

A medida que el sistema crece, podemos optimizar a√∫n m√°s el cach√©. Por ejemplo, podr√≠amos implementar cach√© de segundo nivel para datos que cambian muy raramente (como cat√°logos). Podr√≠amos usar t√©cnicas de pre-caching para anticipar qu√© datos los usuarios van a necesitar.

Pero por ahora, el sistema de cach√© actual es m√°s que suficiente. Hace que el sistema sea r√°pido, responsivo, y agradable de usar. Y eso es lo m√°s importante.

---

*Documento narrativo del sistema de cach√© - Diciembre 2025*  
*Versi√≥n del Sistema: Chequeo Digital 2.0*

